{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Experiment 1",
   "id": "9e704b740dfc4acd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T21:14:28.380558Z",
     "start_time": "2024-07-03T21:14:28.158833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "361d3a33c84134a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "e9c145d80440ea57"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T23:54:06.473285Z",
     "start_time": "2024-07-03T23:54:03.831709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torch import nn, optim\n",
    "from torchinfo import summary\n",
    "\n",
    "from plant_village_dataset import PlantVillageDataset\n",
    "from runner import Runner\n",
    "from mlp import MLP\n",
    "from convnext import ConvNext\n",
    "from encoder_mlp import EncoderMLP\n",
    "from unet_autoencoder import UNetAutoencoder, UNetEncoder, UNetDecoder"
   ],
   "id": "d518676c9749b0b0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare Data",
   "id": "ef6e119d55682dc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T21:14:28.410335Z",
     "start_time": "2024-07-03T21:14:28.397639Z"
    }
   },
   "cell_type": "code",
   "source": "DEVICE = 'mps'",
   "id": "3bb05eeeb2d69862",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T21:14:28.424979Z",
     "start_time": "2024-07-03T21:14:28.411994Z"
    }
   },
   "cell_type": "code",
   "source": "BATCH_SIZE = 64",
   "id": "9ff4e1516b8f6e40",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T21:14:28.442549Z",
     "start_time": "2024-07-03T21:14:28.426019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split(dataset, batch_size, labeled_ratio, test_ratio):    \n",
    "    labels = dataset.get_labels()\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    unlabeled_indices, labeled_indices = train_test_split(np.arange(len(dataset)),\n",
    "                                                          test_size=labeled_ratio,\n",
    "                                                          stratify=labels)   \n",
    "    \n",
    "    ul_train_indices, ul_val_indices = train_test_split(unlabeled_indices, test_size=0.1)\n",
    "    \n",
    "    relative_test_ratio = test_ratio / labeled_ratio\n",
    "    \n",
    "    train_val_indices, test_indices = train_test_split(labeled_indices,\n",
    "                                                       test_size=relative_test_ratio,\n",
    "                                                       stratify=labels[labeled_indices])\n",
    "    \n",
    "    train_indices, val_indices = train_test_split(train_val_indices,\n",
    "                                                  test_size=0.2,\n",
    "                                                  stratify=labels[train_val_indices])\n",
    "\n",
    "    ul_train_sampler = SubsetRandomSampler(ul_train_indices)\n",
    "    ul_val_sampler = SubsetRandomSampler(ul_val_indices)\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(val_indices)\n",
    "    test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "    ul_train_loader = DataLoader(dataset, batch_size=batch_size, sampler=ul_train_sampler, num_workers=12)\n",
    "    ul_val_loader = DataLoader(dataset, batch_size=batch_size, sampler=ul_val_sampler, num_workers=12)\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=12)\n",
    "    val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_sampler, num_workers=12)\n",
    "    test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler, num_workers=12)\n",
    "\n",
    "    return ul_train_loader, ul_val_loader, train_loader, val_loader, test_loader"
   ],
   "id": "2ef1dbcc41c8dd49",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T21:14:28.457382Z",
     "start_time": "2024-07-03T21:14:28.443353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ReconstructionDataLoader:\n",
    "    def __init__(self, base_loader):\n",
    "        self.base_loader = base_loader\n",
    "\n",
    "    def __iter__(self):\n",
    "        for data in self.base_loader:\n",
    "            images, _ = data  # Ignore labels or other types of data\n",
    "            yield images, images  # Yield images as both input and target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_loader)"
   ],
   "id": "f233d4efacb0a40e",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T23:54:13.893691Z",
     "start_time": "2024-07-03T23:54:08.455076Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = PlantVillageDataset('images')",
   "id": "e03f52ea1e1296c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Plant Village\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ariel.arevalo/Workspace/ci0148/proyecto_2/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Normalizing dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " - Calculating mean and standard deviation:   0%|          | 0/867 [00:00<?, ?batch/s]Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.9/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.9/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ariel.arevalo/Workspace/ci0148/proyecto_2/venv/lib/python3.11/site-packages/torch/__init__.py\", line 1896, in <module>\n",
      "    from torch import export as export\n",
      "  File \"/Users/ariel.arevalo/Workspace/ci0148/proyecto_2/venv/lib/python3.11/site-packages/torch/export/__init__.py\", line 64, in <module>\n",
      " - Calculating mean and standard deviation:   0%|          | 0/867 [00:04<?, ?batch/s]\n",
      "    from .dynamic_shapes import Constraint, Dim, dims, dynamic_dim\n",
      "  File \"/Users/ariel.arevalo/Workspace/ci0148/proyecto_2/venv/lib/python3.11/site-packages/torch/export/dynamic_shapes.py\", line 14, in <module>\n",
      "    from .exported_program import ExportedProgram\n",
      "  File \"/Users/ariel.arevalo/Workspace/ci0148/proyecto_2/venv/lib/python3.11/site-packages/torch/export/exported_program.py\", line 35, in <module>\n",
      "    from torch.fx.experimental.proxy_tensor import maybe_disable_fake_tensor_mode\n",
      "  File \"/Users/ariel.arevalo/Workspace/ci0148/proyecto_2/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 39, in <module>\n",
      "    from ._backward_state import BackwardState\n",
      "  File \"/Users/ariel.arevalo/Workspace/ci0148/proyecto_2/venv/lib/python3.11/site-packages/torch/fx/experimental/_backward_state.py\", line 1, in <module>\n",
      "    import torch.fx\n",
      "  File \"<frozen importlib._bootstrap>\", line 224, in _lock_unlock_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 110, in acquire\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mPlantVillageDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mimages\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Workspace/ci0148/proyecto_3/src/plant_village_dataset.py:27\u001B[0m, in \u001B[0;36mPlantVillageDataset.__init__\u001B[0;34m(self, root)\u001B[0m\n\u001B[1;32m     24\u001B[0m nb_samples \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# Iterate over the dataset\u001B[39;00m\n\u001B[0;32m---> 27\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtqdm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdesc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m - Calculating mean and standard deviation\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43munit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbatch\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_samples\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# get the batch size\u001B[39;49;00m\n\u001B[1;32m     29\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mview\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[43m                     \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# flatten the image pixels except for batch and channel dimensions\u001B[39;49;00m\n",
      "File \u001B[0;32m~/Workspace/ci0148/proyecto_2/venv/lib/python3.11/site-packages/tqdm/std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1178\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1181\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1182\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\n\u001B[1;32m   1183\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Update and possibly print the progressbar.\u001B[39;49;00m\n\u001B[1;32m   1184\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;49;00m\n",
      "File \u001B[0;32m~/Workspace/ci0148/proyecto_2/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:439\u001B[0m, in \u001B[0;36mDataLoader.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    437\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator\n\u001B[1;32m    438\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 439\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Workspace/ci0148/proyecto_2/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:387\u001B[0m, in \u001B[0;36mDataLoader._get_iterator\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    385\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    386\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_worker_number_rationality()\n\u001B[0;32m--> 387\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_MultiProcessingDataLoaderIter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Workspace/ci0148/proyecto_2/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1040\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter.__init__\u001B[0;34m(self, loader)\u001B[0m\n\u001B[1;32m   1033\u001B[0m w\u001B[38;5;241m.\u001B[39mdaemon \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   1034\u001B[0m \u001B[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001B[39;00m\n\u001B[1;32m   1035\u001B[0m \u001B[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001B[39;00m\n\u001B[1;32m   1036\u001B[0m \u001B[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001B[39;00m\n\u001B[1;32m   1037\u001B[0m \u001B[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001B[39;00m\n\u001B[1;32m   1038\u001B[0m \u001B[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001B[39;00m\n\u001B[1;32m   1039\u001B[0m \u001B[38;5;66;03m#     AssertionError: can only join a started process.\u001B[39;00m\n\u001B[0;32m-> 1040\u001B[0m \u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1041\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_queues\u001B[38;5;241m.\u001B[39mappend(index_queue)\n\u001B[1;32m   1042\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers\u001B[38;5;241m.\u001B[39mappend(w)\n",
      "File \u001B[0;32m/opt/homebrew/Cellar/python@3.11/3.11.9/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py:121\u001B[0m, in \u001B[0;36mBaseProcess.start\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _current_process\u001B[38;5;241m.\u001B[39m_config\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemon\u001B[39m\u001B[38;5;124m'\u001B[39m), \\\n\u001B[1;32m    119\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemonic processes are not allowed to have children\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    120\u001B[0m _cleanup()\n\u001B[0;32m--> 121\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sentinel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen\u001B[38;5;241m.\u001B[39msentinel\n\u001B[1;32m    123\u001B[0m \u001B[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001B[39;00m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;66;03m# reference to the process object (see bpo-30775)\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Cellar/python@3.11/3.11.9/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/context.py:224\u001B[0m, in \u001B[0;36mProcess._Popen\u001B[0;34m(process_obj)\u001B[0m\n\u001B[1;32m    222\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[1;32m    223\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[0;32m--> 224\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mProcess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Cellar/python@3.11/3.11.9/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/context.py:288\u001B[0m, in \u001B[0;36mSpawnProcess._Popen\u001B[0;34m(process_obj)\u001B[0m\n\u001B[1;32m    285\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[1;32m    286\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[1;32m    287\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpopen_spawn_posix\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Popen\n\u001B[0;32m--> 288\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Cellar/python@3.11/3.11.9/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_spawn_posix.py:32\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[0;34m(self, process_obj)\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, process_obj):\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fds \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m---> 32\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Cellar/python@3.11/3.11.9/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_fork.py:19\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[0;34m(self, process_obj)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturncode \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfinalizer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m---> 19\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_launch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Cellar/python@3.11/3.11.9/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_spawn_posix.py:62\u001B[0m, in \u001B[0;36mPopen._launch\u001B[0;34m(self, process_obj)\u001B[0m\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msentinel \u001B[38;5;241m=\u001B[39m parent_r\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(parent_w, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m'\u001B[39m, closefd\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m---> 62\u001B[0m         f\u001B[38;5;241m.\u001B[39mwrite(fp\u001B[38;5;241m.\u001B[39mgetbuffer())\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     64\u001B[0m     fds_to_close \u001B[38;5;241m=\u001B[39m []\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T21:16:44.862326Z",
     "start_time": "2024-07-03T21:16:44.826215Z"
    }
   },
   "cell_type": "code",
   "source": "idx_to_class = {v: k for k, v in dataset.class_to_idx.items()}",
   "id": "8870415797e29be1",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run 1",
   "id": "b43c40dfa82eccf2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T21:19:52.217941Z",
     "start_time": "2024-07-03T21:16:44.863588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ul_train_loader, ul_val_loader, train_loader, val_loader, test_loader = split(dataset, batch_size=BATCH_SIZE, labeled_ratio=0.2, test_ratio=0.1)\n",
    "\n",
    "ul_train_loader = ReconstructionDataLoader(ul_train_loader)\n",
    "ul_val_loader = ReconstructionDataLoader(ul_val_loader)"
   ],
   "id": "dbf2b9b8d12ec21e",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### CNN",
   "id": "1666a4be9986accd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T21:41:15.818524Z",
     "start_time": "2024-07-03T21:19:52.220777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cnn = ConvNext(num_classes=len(dataset.classes))\n",
    "cnn_optim = optim.Adam(cnn.parameters(), lr=1e-4)\n",
    "cnn_criterion = nn.CrossEntropyLoss()\n",
    "cnn_runner = Runner('cnn_1', cnn, cnn_optim, cnn_criterion, DEVICE)\n",
    "cnn_runner.train(train_loader, val_loader, num_epochs=3)\n",
    "cnn_runner.test(test_loader, idx_to_class)"
   ],
   "id": "421ff10c200ab128",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/3 [00:00<?, ? epoch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "61844fd118cf4b2babd0236db0fb926a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/70 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "062fda70939d4c94b1618bead5c2fa41"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validating:   0%|          | 0/18 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec94557a549041cd990978294e4bbc5f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Train Loss: 2.0144, Validation Loss: 0.9056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/70 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b06e8d496dd4614ab71a3c165d59c00"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[48], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m cnn_criterion \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss()\n\u001B[1;32m      4\u001B[0m cnn_runner \u001B[38;5;241m=\u001B[39m Runner(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcnn_1\u001B[39m\u001B[38;5;124m'\u001B[39m, cnn, cnn_optim, cnn_criterion, DEVICE)\n\u001B[0;32m----> 5\u001B[0m \u001B[43mcnn_runner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m cnn_runner\u001B[38;5;241m.\u001B[39mtest(test_loader, idx_to_class)\n",
      "File \u001B[0;32m~/Workspace/ci0148/proyecto_3/src/runner.py:42\u001B[0m, in \u001B[0;36mRunner.train\u001B[0;34m(self, train_loader, val_loader, num_epochs, patience, val_loss_target)\u001B[0m\n\u001B[1;32m     39\u001B[0m epochs_without_improvement \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m trange(num_epochs, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTraining\u001B[39m\u001B[38;5;124m'\u001B[39m, unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m epoch\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m---> 42\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     43\u001B[0m     val_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_model(val_loader)\n\u001B[1;32m     45\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m val_loss \u001B[38;5;241m<\u001B[39m best_val_loss:\n",
      "File \u001B[0;32m~/Workspace/ci0148/proyecto_3/src/runner.py:148\u001B[0m, in \u001B[0;36mRunner._train_model\u001B[0;34m(self, train_loader)\u001B[0m\n\u001B[1;32m    145\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m    146\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m--> 148\u001B[0m     running_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    150\u001B[0m avg_loss \u001B[38;5;241m=\u001B[39m running_loss \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(train_loader)\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m avg_loss\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Autoencoder",
   "id": "a7691eb99adf809a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T21:41:15.819674Z",
     "start_time": "2024-07-03T21:41:15.819512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "uae = UNetAutoencoder()\n",
    "uae_optim = optim.Adam(uae.parameters(), lr=1e-3)\n",
    "uae_criterion = nn.MSELoss()\n",
    "uae_runner = Runner('uae_1', uae, uae_optim, uae_criterion, DEVICE)\n",
    "uae_runner.train(ul_train_loader, ul_val_loader, num_epochs=3)\n",
    "\n",
    "enc = uae.encoder"
   ],
   "id": "f117d9666726abad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Frozen Encoder + MLP",
   "id": "c9cee173c920a494"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlp = MLP(input_size=512, hidden_sizes=[2048, 1024, 512, 256], output_size=len(dataset.classes), dropout_rate=0.2)\n",
    "emlp = EncoderMLP(encoder=enc, mlp=mlp)\n",
    "emlp_optim = optim.Adam(emlp.parameters(), lr=1e-4)\n",
    "emlp_criterion = nn.CrossEntropyLoss()\n",
    "emlp_runner = Runner('emlp_1_a', emlp, emlp_optim, emlp_criterion, DEVICE)\n",
    "emlp.freeze_encoder()\n",
    "emlp_runner.train(train_loader, val_loader, num_epochs=15)\n",
    "emlp_runner.test(test_loader, idx_to_class)"
   ],
   "id": "3d5bd6b5cc4043ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Live Encoder + MLP",
   "id": "a2b0e3ea23932c62"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlp = MLP(input_size=512, hidden_sizes=[2048, 1024, 512, 256], output_size=len(dataset.classes), dropout_rate=0.2)\n",
    "emlp = EncoderMLP(encoder=enc, mlp=mlp)\n",
    "emlp_optim = optim.Adam(emlp.parameters(), lr=1e-4)\n",
    "emlp_criterion = nn.CrossEntropyLoss()\n",
    "emlp_runner = Runner('emlp_1_b', emlp, emlp_optim, emlp_criterion, DEVICE)\n",
    "emlp.unfreeze_encoder()\n",
    "emlp_runner.train(train_loader, val_loader, num_epochs=15)\n",
    "emlp_runner.test(test_loader, idx_to_class)"
   ],
   "id": "318ebd8e00d45b27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run 2",
   "id": "1a298c93ed84b932"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ul_train_loader, ul_val_loader, train_loader, val_loader, test_loader = split(dataset, batch_size=BATCH_SIZE, labeled_ratio=0.5, test_ratio=0.15)\n",
    "\n",
    "ul_train_loader = ReconstructionDataLoader(ul_train_loader)\n",
    "ul_val_loader = ReconstructionDataLoader(ul_val_loader)"
   ],
   "id": "cc8f297e104c3c5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### CNN",
   "id": "b189faece320347"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cnn = ConvNext(num_classes=len(dataset.classes))\n",
    "cnn_optim = optim.Adam(cnn.parameters(), lr=1e-4)\n",
    "cnn_criterion = nn.CrossEntropyLoss()\n",
    "cnn_runner = Runner('cnn_2', cnn, cnn_optim, cnn_criterion, DEVICE)\n",
    "cnn_runner.train(train_loader, val_loader, num_epochs=3)\n",
    "cnn_runner.test(test_loader, idx_to_class)"
   ],
   "id": "3d31c5b8240c0b64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Autoencoder",
   "id": "aeef25d8cd5f709e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "uae = UNetAutoencoder()\n",
    "uae_optim = optim.Adam(uae.parameters(), lr=1e-3)\n",
    "uae_criterion = nn.MSELoss()\n",
    "uae_runner = Runner('uae_2', uae, uae_optim, uae_criterion, DEVICE)\n",
    "uae_runner.train(ul_train_loader, ul_val_loader, num_epochs=3)\n",
    "\n",
    "enc = uae.encoder"
   ],
   "id": "110890e30ce793c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Frozen Encoder + MLP",
   "id": "3c1415119f710d42"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlp = MLP(input_size=512, hidden_sizes=[2048, 1024, 512, 256], output_size=len(dataset.classes), dropout_rate=0.2)\n",
    "emlp = EncoderMLP(encoder=enc, mlp=mlp)\n",
    "emlp_optim = optim.Adam(emlp.parameters(), lr=1e-4)\n",
    "emlp_criterion = nn.CrossEntropyLoss()\n",
    "emlp_runner = Runner('emlp_2_a', emlp, emlp_optim, emlp_criterion, DEVICE)\n",
    "emlp.freeze_encoder()\n",
    "emlp_runner.train(train_loader, val_loader, num_epochs=15)\n",
    "emlp_runner.test(test_loader, idx_to_class)"
   ],
   "id": "9c2eebcf33912d50",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Live Encoder + MLP",
   "id": "f6d8f10762e55cf2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlp = MLP(input_size=512, hidden_sizes=[2048, 1024, 512, 256], output_size=len(dataset.classes), dropout_rate=0.2)\n",
    "emlp = EncoderMLP(encoder=enc, mlp=mlp)\n",
    "emlp_optim = optim.Adam(emlp.parameters(), lr=1e-4)\n",
    "emlp_criterion = nn.CrossEntropyLoss()\n",
    "emlp_runner = Runner('emlp_2_b', emlp, emlp_optim, emlp_criterion, DEVICE)\n",
    "emlp.unfreeze_encoder()\n",
    "emlp_runner.train(train_loader, val_loader, num_epochs=15)\n",
    "emlp_runner.test(test_loader, idx_to_class)"
   ],
   "id": "88a1295c0b569f64",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

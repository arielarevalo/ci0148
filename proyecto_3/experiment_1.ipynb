{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Experiment 1",
   "id": "9e704b740dfc4acd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T21:14:28.380558Z",
     "start_time": "2024-07-03T21:14:28.158833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "361d3a33c84134a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "e9c145d80440ea57"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T21:14:28.397006Z",
     "start_time": "2024-07-03T21:14:28.381963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torch import nn, optim\n",
    "from torchinfo import summary\n",
    "\n",
    "from plant_village_dataset import PlantVillageDataset\n",
    "from runner import Runner\n",
    "from mlp import MLP\n",
    "from convnext import ConvNext\n",
    "from encoder_mlp import EncoderMLP\n",
    "from unet_autoencoder import UNetAutoencoder, UNetEncoder, UNetDecoder"
   ],
   "id": "d518676c9749b0b0",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare Data",
   "id": "ef6e119d55682dc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T21:14:28.410335Z",
     "start_time": "2024-07-03T21:14:28.397639Z"
    }
   },
   "cell_type": "code",
   "source": "DEVICE = 'mps'",
   "id": "3bb05eeeb2d69862",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T21:14:28.424979Z",
     "start_time": "2024-07-03T21:14:28.411994Z"
    }
   },
   "cell_type": "code",
   "source": "BATCH_SIZE = 64",
   "id": "9ff4e1516b8f6e40",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T21:14:28.442549Z",
     "start_time": "2024-07-03T21:14:28.426019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split(dataset, batch_size, labeled_ratio, test_ratio):    \n",
    "    labels = dataset.get_labels()\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    unlabeled_indices, labeled_indices = train_test_split(np.arange(len(dataset)),\n",
    "                                                          test_size=labeled_ratio,\n",
    "                                                          stratify=labels)   \n",
    "    \n",
    "    ul_train_indices, ul_val_indices = train_test_split(unlabeled_indices, test_size=0.1)\n",
    "    \n",
    "    relative_test_ratio = test_ratio / labeled_ratio\n",
    "    \n",
    "    train_val_indices, test_indices = train_test_split(labeled_indices,\n",
    "                                                       test_size=relative_test_ratio,\n",
    "                                                       stratify=labels[labeled_indices])\n",
    "    \n",
    "    train_indices, val_indices = train_test_split(train_val_indices,\n",
    "                                                  test_size=0.2,\n",
    "                                                  stratify=labels[train_val_indices])\n",
    "\n",
    "    ul_train_sampler = SubsetRandomSampler(ul_train_indices)\n",
    "    ul_val_sampler = SubsetRandomSampler(ul_val_indices)\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(val_indices)\n",
    "    test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "    ul_train_loader = DataLoader(dataset, batch_size=batch_size, sampler=ul_train_sampler)\n",
    "    ul_val_loader = DataLoader(dataset, batch_size=batch_size, sampler=ul_val_sampler)\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)\n",
    "    test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n",
    "\n",
    "    return ul_train_loader, ul_val_loader, train_loader, val_loader, test_loader"
   ],
   "id": "2ef1dbcc41c8dd49",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T21:14:28.457382Z",
     "start_time": "2024-07-03T21:14:28.443353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ReconstructionDataLoader:\n",
    "    def __init__(self, base_loader):\n",
    "        self.base_loader = base_loader\n",
    "\n",
    "    def __iter__(self):\n",
    "        for data in self.base_loader:\n",
    "            images, _ = data  # Ignore labels or other types of data\n",
    "            yield images, images  # Yield images as both input and target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_loader)"
   ],
   "id": "f233d4efacb0a40e",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T21:16:44.823758Z",
     "start_time": "2024-07-03T21:14:28.458265Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = PlantVillageDataset('images')",
   "id": "e03f52ea1e1296c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Plant Village\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ariel.arevalo/Workspace/ci0148/proyecto_2/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Normalizing dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " - Calculating mean and standard deviation: 100%|██████████| 867/867 [02:16<00:00,  6.37batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Normalized dataset:\n",
      "  - Mean: [0.4671, 0.4895, 0.4123]\n",
      "  - Standard deviation: [0.1709, 0.1443, 0.1880]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T21:16:44.862326Z",
     "start_time": "2024-07-03T21:16:44.826215Z"
    }
   },
   "cell_type": "code",
   "source": "idx_to_class = {v: k for k, v in dataset.class_to_idx.items()}",
   "id": "8870415797e29be1",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run 1",
   "id": "b43c40dfa82eccf2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T21:19:52.217941Z",
     "start_time": "2024-07-03T21:16:44.863588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ul_train_loader, ul_val_loader, train_loader, val_loader, test_loader = split(dataset, batch_size=BATCH_SIZE, labeled_ratio=0.2, test_ratio=0.1)\n",
    "\n",
    "ul_train_loader = ReconstructionDataLoader(ul_train_loader)\n",
    "ul_val_loader = ReconstructionDataLoader(ul_val_loader)"
   ],
   "id": "dbf2b9b8d12ec21e",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### CNN",
   "id": "1666a4be9986accd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T21:41:15.818524Z",
     "start_time": "2024-07-03T21:19:52.220777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cnn = ConvNext(num_classes=len(dataset.classes))\n",
    "cnn_optim = optim.Adam(cnn.parameters(), lr=1e-4)\n",
    "cnn_criterion = nn.CrossEntropyLoss()\n",
    "cnn_runner = Runner('cnn_1', cnn, cnn_optim, cnn_criterion, DEVICE)\n",
    "cnn_runner.train(train_loader, val_loader, num_epochs=3)\n",
    "cnn_runner.test(test_loader, idx_to_class)"
   ],
   "id": "421ff10c200ab128",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/3 [00:00<?, ? epoch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "61844fd118cf4b2babd0236db0fb926a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/70 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "062fda70939d4c94b1618bead5c2fa41"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validating:   0%|          | 0/18 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec94557a549041cd990978294e4bbc5f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Train Loss: 2.0144, Validation Loss: 0.9056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/70 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b06e8d496dd4614ab71a3c165d59c00"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[48], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m cnn_criterion \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss()\n\u001B[1;32m      4\u001B[0m cnn_runner \u001B[38;5;241m=\u001B[39m Runner(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcnn_1\u001B[39m\u001B[38;5;124m'\u001B[39m, cnn, cnn_optim, cnn_criterion, DEVICE)\n\u001B[0;32m----> 5\u001B[0m \u001B[43mcnn_runner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m cnn_runner\u001B[38;5;241m.\u001B[39mtest(test_loader, idx_to_class)\n",
      "File \u001B[0;32m~/Workspace/ci0148/proyecto_3/src/runner.py:42\u001B[0m, in \u001B[0;36mRunner.train\u001B[0;34m(self, train_loader, val_loader, num_epochs, patience, val_loss_target)\u001B[0m\n\u001B[1;32m     39\u001B[0m epochs_without_improvement \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m trange(num_epochs, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTraining\u001B[39m\u001B[38;5;124m'\u001B[39m, unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m epoch\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m---> 42\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     43\u001B[0m     val_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_model(val_loader)\n\u001B[1;32m     45\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m val_loss \u001B[38;5;241m<\u001B[39m best_val_loss:\n",
      "File \u001B[0;32m~/Workspace/ci0148/proyecto_3/src/runner.py:148\u001B[0m, in \u001B[0;36mRunner._train_model\u001B[0;34m(self, train_loader)\u001B[0m\n\u001B[1;32m    145\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m    146\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m--> 148\u001B[0m     running_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    150\u001B[0m avg_loss \u001B[38;5;241m=\u001B[39m running_loss \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(train_loader)\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m avg_loss\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Autoencoder",
   "id": "a7691eb99adf809a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T21:41:15.819674Z",
     "start_time": "2024-07-03T21:41:15.819512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "uae = UNetAutoencoder()\n",
    "uae_optim = optim.Adam(uae.parameters(), lr=1e-3)\n",
    "uae_criterion = nn.MSELoss()\n",
    "uae_runner = Runner('uae_1', uae, uae_optim, uae_criterion, DEVICE)\n",
    "uae_runner.train(ul_train_loader, ul_val_loader, num_epochs=3)\n",
    "\n",
    "enc = uae.encoder"
   ],
   "id": "f117d9666726abad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Frozen Encoder + MLP",
   "id": "c9cee173c920a494"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlp = MLP(input_size=512, hidden_sizes=[1024, 512, 256], output_size=len(dataset.classes), dropout_rate=0.3)\n",
    "emlp = EncoderMLP(encoder=enc, mlp=mlp)\n",
    "emlp_optim = optim.Adam(emlp.parameters(), lr=5e-4)\n",
    "emlp_criterion = nn.CrossEntropyLoss()\n",
    "emlp_runner = Runner('emlp_1_a', emlp, emlp_optim, emlp_criterion, DEVICE)\n",
    "emlp.freeze_encoder()\n",
    "emlp_runner.train(train_loader, val_loader, num_epochs=15)\n",
    "emlp_runner.test(test_loader, idx_to_class)"
   ],
   "id": "3d5bd6b5cc4043ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Live Encoder + MLP",
   "id": "a2b0e3ea23932c62"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlp = MLP(input_size=512, hidden_sizes=[1024, 512, 256], output_size=len(dataset.classes), dropout_rate=0.3)\n",
    "emlp = EncoderMLP(encoder=enc, mlp=mlp)\n",
    "emlp_optim = optim.Adam(emlp.parameters(), lr=1e-4)\n",
    "emlp_criterion = nn.CrossEntropyLoss()\n",
    "emlp_runner = Runner('emlp_1_b', emlp, emlp_optim, emlp_criterion, DEVICE)\n",
    "emlp.unfreeze_encoder()\n",
    "emlp_runner.train(train_loader, val_loader, num_epochs=15)\n",
    "emlp_runner.test(test_loader, idx_to_class)"
   ],
   "id": "318ebd8e00d45b27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Cleanup",
   "id": "8afa0c5881e52373"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "del ul_train_loader, ul_val_loader, train_loader, val_loader, test_loader\n",
    "gc.collect()"
   ],
   "id": "ccb9ac5d7e90d2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run 2",
   "id": "1a298c93ed84b932"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ul_train_loader, ul_val_loader, train_loader, val_loader, test_loader = split(dataset, batch_size=BATCH_SIZE, labeled_ratio=0.5, test_ratio=0.15)\n",
    "\n",
    "ul_train_loader = ReconstructionDataLoader(ul_train_loader)\n",
    "ul_val_loader = ReconstructionDataLoader(ul_val_loader)"
   ],
   "id": "cc8f297e104c3c5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### CNN",
   "id": "b189faece320347"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cnn = ConvNext(num_classes=len(dataset.classes))\n",
    "cnn_optim = optim.Adam(cnn.parameters(), lr=1e-4)\n",
    "cnn_criterion = nn.CrossEntropyLoss()\n",
    "cnn_runner = Runner('cnn_2', cnn, cnn_optim, cnn_criterion, DEVICE)\n",
    "cnn_runner.train(train_loader, val_loader, num_epochs=3)\n",
    "cnn_runner.test(test_loader, idx_to_class)"
   ],
   "id": "3d31c5b8240c0b64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Autoencoder",
   "id": "aeef25d8cd5f709e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "uae = UNetAutoencoder()\n",
    "uae_optim = optim.Adam(uae.parameters(), lr=1e-3)\n",
    "uae_criterion = nn.MSELoss()\n",
    "uae_runner = Runner('uae_2', uae, uae_optim, uae_criterion, DEVICE)\n",
    "uae_runner.train(ul_train_loader, ul_val_loader, num_epochs=3)\n",
    "\n",
    "enc = uae.encoder"
   ],
   "id": "110890e30ce793c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Frozen Encoder + MLP",
   "id": "3c1415119f710d42"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlp = MLP(input_size=512, hidden_sizes=[1024, 512, 256], output_size=len(dataset.classes), dropout_rate=0.3)\n",
    "emlp = EncoderMLP(encoder=enc, mlp=mlp)\n",
    "emlp_optim = optim.Adam(emlp.parameters(), lr=1e-4)\n",
    "emlp_criterion = nn.CrossEntropyLoss()\n",
    "emlp_runner = Runner('emlp_2_a', emlp, emlp_optim, emlp_criterion, DEVICE)\n",
    "emlp.freeze_encoder()\n",
    "emlp_runner.train(train_loader, val_loader, num_epochs=15)\n",
    "emlp_runner.test(test_loader, idx_to_class)"
   ],
   "id": "9c2eebcf33912d50",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Live Encoder + MLP",
   "id": "f6d8f10762e55cf2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlp = MLP(input_size=512, hidden_sizes=[1024, 512, 256], output_size=len(dataset.classes), dropout_rate=0.3)\n",
    "emlp = EncoderMLP(encoder=enc, mlp=mlp)\n",
    "emlp_optim = optim.Adam(emlp.parameters(), lr=1e-4)\n",
    "emlp_criterion = nn.CrossEntropyLoss()\n",
    "emlp_runner = Runner('emlp_2_b', emlp, emlp_optim, emlp_criterion, DEVICE)\n",
    "emlp.unfreeze_encoder()\n",
    "emlp_runner.train(train_loader, val_loader, num_epochs=15)\n",
    "emlp_runner.test(test_loader, idx_to_class)"
   ],
   "id": "88a1295c0b569f64",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

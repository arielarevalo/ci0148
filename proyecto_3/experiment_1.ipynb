{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Experiment 1",
   "id": "9e704b740dfc4acd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "361d3a33c84134a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "e9c145d80440ea57"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torch import nn, optim\n",
    "\n",
    "from plant_village_dataset import PlantVillageDataset\n",
    "from runner import Runner\n",
    "from resnet50 import ResNet50"
   ],
   "id": "d518676c9749b0b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Prepare Data\n",
    "\n",
    "Here we define the split according to project specifications, with the decision made to interpret 10% of the dataset to be used for training as including both the training and validation data, and the 10% for testing to be used wholly for testing proper."
   ],
   "id": "ef6e119d55682dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "BATCH_SIZE = 128",
   "id": "9ff4e1516b8f6e40",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def split(dataset, batch_size, labeled_ratio, test_ratio):    \n",
    "    labels = np.array([label for _, label in dataset])\n",
    "\n",
    "    unlabeled_indices, labeled_indices = train_test_split(np.arange(len(dataset)),\n",
    "                                                          test_size=labeled_ratio,\n",
    "                                                          stratify=labels)   \n",
    "    \n",
    "    relative_test_ratio = test_ratio / labeled_ratio\n",
    "    \n",
    "    train_val_indices, test_indices = train_test_split(labeled_indices,\n",
    "                                                       test_size=relative_test_ratio,\n",
    "                                                       stratify=labels[labeled_indices])\n",
    "    \n",
    "    train_indices, val_indices = train_test_split(train_val_indices,\n",
    "                                                  test_size=0.2,\n",
    "                                                  stratify=labels[train_val_indices])\n",
    "\n",
    "    unlabeled_sampler = SubsetRandomSampler(unlabeled_indices)\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(val_indices)\n",
    "    test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "    unlabeled_loader = DataLoader(dataset, batch_size=batch_size, sampler=unlabeled_sampler)\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)\n",
    "    test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n",
    "\n",
    "    return unlabeled_loader, train_loader, val_loader, test_loader"
   ],
   "id": "2ef1dbcc41c8dd49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dataset = PlantVillageDataset('images')",
   "id": "e03f52ea1e1296c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run 1",
   "id": "b43c40dfa82eccf2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "unlabeled_loader, train_loader, val_loader, test_loader = split(dataset, batch_size=BATCH_SIZE, labeled_ratio=0.2, test_ratio=0.1)",
   "id": "dbf2b9b8d12ec21e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### CNN",
   "id": "1666a4be9986accd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cnn = ResNet50(num_classes=len(dataset.classes))\n",
    "cnn_optim = optim.Adam(cnn.parameters(), lr=1e-3)\n",
    "cnn_criterion = nn.CrossEntropyLoss()\n",
    "cnn_runner = Runner('cnn_1', cnn, cnn_optim, cnn_criterion, device='mps')\n",
    "cnn_runner.train(train_loader, val_loader, num_epochs=3)\n",
    "cnn_runner.test(test_loader)\n",
    "pass"
   ],
   "id": "c626dea4aae28011",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Autoencoder",
   "id": "a7691eb99adf809a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Declare UNetAutoEncoder\n",
    "# Train UNetAutoEncoder\n",
    "# Extract Encoder from UNetAutoEncoder"
   ],
   "id": "f117d9666726abad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Frozen Encoder + MLP",
   "id": "c9cee173c920a494"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Train one Frankenstein with the Encoder's weights set to eval() (Frozen)",
   "id": "3d5bd6b5cc4043ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Live Encoder + MLP",
   "id": "a2b0e3ea23932c62"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Train the second Frankenstein normally",
   "id": "318ebd8e00d45b27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run 2",
   "id": "1a298c93ed84b932"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "unlabeled_loader, train_loader, val_loader, test_loader = split(dataset, batch_size=BATCH_SIZE, labeled_ratio=0.5, test_ratio=0.15)",
   "id": "cc8f297e104c3c5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### CNN",
   "id": "b189faece320347"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cnn = ResNet50(num_classes=len(dataset.classes))\n",
    "cnn_optim = optim.Adam(cnn.parameters(), lr=1e-3)\n",
    "cnn_criterion = nn.CrossEntropyLoss()\n",
    "cnn_runner = Runner('cnn_2', cnn, cnn_optim, cnn_criterion, device='mps')\n",
    "cnn_runner.train(train_loader, val_loader, num_epochs=3)\n",
    "cnn_runner.test(test_loader)\n",
    "pass"
   ],
   "id": "2f9e64879ae2bc33",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Autoencoder",
   "id": "aeef25d8cd5f709e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Declare UNetAutoEncoder\n",
    "# Train UNetAutoEncoder\n",
    "# Extract Encoder from UNetAutoEncoder"
   ],
   "id": "110890e30ce793c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Frozen Encoder + MLP",
   "id": "3c1415119f710d42"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Train one Frankenstein with the Encoder's weights set to eval() (Frozen)",
   "id": "9c2eebcf33912d50",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Live Encoder + MLP",
   "id": "f6d8f10762e55cf2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Train the second Frankenstein normally",
   "id": "88a1295c0b569f64",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
